{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "607725b9-7398-415f-a526-a8a22350540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\shang\\anaconda3\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shang\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\shang\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\shang\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.31.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\shang\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\shang\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\shang\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\shang\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shang\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: tf-keras in c:\\users\\shang\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2025.7.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\shang\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\shang\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\shang\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shang\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!conda install pip -y\n",
    "!pip install -U sentence-transformers\n",
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dd530eb-53e5-4fa1-b707-d74bebd01e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29694932-12b6-4bbd-9faa-6ddcbe534dcc",
   "metadata": {},
   "source": [
    "## Install PDF Support (for PyMuPDF)\n",
    "\n",
    "Required for extracting resume text from uploaded PDF files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e60f44f8-0e6d-4eb0-8fac-77f2081fbe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\shang\\anaconda3\\lib\\site-packages (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "# Uncomment if running in a fresh environment\n",
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a524c243-2841-45e9-83bc-b2ca15484017",
   "metadata": {},
   "source": [
    "## Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "216b5a1c-27c5-4925-bcd5-235e1889a6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume dataset columns: ['ID', 'Resume_str', 'Resume_html', 'Category']\n",
      "Job dataset columns: ['Document ID', 'Job Title', 'Job Description']\n"
     ]
    }
   ],
   "source": [
    "queries_df = pd.read_csv('../data/Resume.csv')  # Resumes as queries\n",
    "documents_df = pd.read_csv('../data/job_title_des.csv')  # Jobs as documents\n",
    "\n",
    "print(\"Resume dataset columns:\", queries_df.columns.tolist())\n",
    "print(\"Job dataset columns:\", documents_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2d6e5-6870-4ab9-868f-38be49e1db4f",
   "metadata": {},
   "source": [
    "## Filter Resumes for Tech-Related Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7feb6353-eb16-4660-8d86-0183fe4e04cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df['Category'] = queries_df['Category'].str.upper().str.strip()\n",
    "target_categories = ['INFORMATION-TECHNOLOGY']  \n",
    "filtered_queries = queries_df[queries_df['Category'].isin(target_categories)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992730f7-8240-4ab0-8e82-c5c1c0ce63ca",
   "metadata": {},
   "source": [
    "## Basic Text Preprocessing\n",
    "\n",
    "- Convert all text to lowercase for consistency.\n",
    "- Strip leading and trailing whitespace.\n",
    "- Apply these cleaning steps to relevant text columns (e.g., job descriptions, resume text).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b0248e1-b71d-4fe9-969f-0265fab873c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.lower().strip()\n",
    "    return \"\"\n",
    "\n",
    "documents_df['cleaned_description'] = documents_df['Job Description'].apply(clean_text)\n",
    "filtered_queries['cleaned_text'] = filtered_queries['Resume_str'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5569410a-8707-49d3-becd-042967b7265b",
   "metadata": {},
   "source": [
    "## PDF Resume Text Extraction and Preprocessing\n",
    "\n",
    "This section defines a helper function to extract text from a PDF resume and clean it using the same preprocessing as the existing resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b93aae99-a6e5-414a-8604-e871ddb28529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "def extract_and_clean_pdf_resume(pdf_path):\n",
    "    \"\"\"Extract and clean text from a PDF resume using PyMuPDF.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return clean_text(text)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0db945bb-c5d2-49b1-b5c9-5edc7dee7dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumes:\n",
      "           ID\n",
      "217  36856210\n",
      "218  21780877\n",
      "219  33241454\n",
      "220  25990239\n",
      "221  16899268\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                cleaned_text\n",
      "217                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     information technology         summary     dedicated  information assurance professional  well-versed in analyzing and mitigating risk and finding cost-effective solutions. excels at boosting performance and productivity by establishing realistic goals and enforcing deadlines.  versatile it professional with 37 years of enterprise design and engineering methodology.       skills          enterprise platforms  knowledge of product lifecycle management (plm)  project tracking  hardware and software upgrade planning  product requirements documentation  self-directed  ms visio  decisive  collaborative  domain active directory layout  data storage engineering      information assurance  risk management framework (rmf)  active directory design and deployment  workstation build and deployment  systems accreditation packages  red hat enterprise linux installation and hardening  network design & troubleshooting   high performance computing            experience      company name    city  ,   state    information technology   02/2011   to   current        i was hired to manage accreditation\\nefforts for a major department modernization project involving 3\\naccreditation packages each leading to successful authorization to\\noperate decisions.  responsibilities then increased to include all\\ndepartmental accreditation efforts leading to another 3 successful\\natos.  now, working on 4 new accreditation including\\nre-authorization for an existing project.  succeeded in writing and\\nimplementing vulnerability management for existing accredited\\nsystems.\\n\\n\\n\\n\\n\\nsuccess\\nof the accreditation hinged on coordination with oni enterprise in\\ncritical design decisions and to help the program integrate smoothly\\ninto the enterprise thru many meetings, analyzing the enterprise\\nbusiness model to understand the best fit for the program.\\n\\n\\n\\n\\n\\nthe\\ndifferent projects required careful management of specific stig\\ncompliance and hardening for the different configurations and\\nservices required for the specific domain to be integrated.   analyzed complex computer systems to assess vulnerability and risk.    supervised  5  external computer consultants and vendors.    managed application patches, data backup, security changes and network configuration.           company name    city  ,   state    systems engineer   02/2006   to   02/2011        i was hired\\nto initiate processing strategies in fulfilling department analyst requirements.  requirements were fulfilled thru i dentifying product problems and strengths and collected data on customer experience  and review of enterprise compliance to transition to new\\ntechnology for supporting new processing needs thru proper processing\\npower.  the next challenge  came as storage requirements for better performance and more\\ncontrolled uses.  after careful study of local infrastructure design, a local storage with off the shelf solutions was\\nadopted to grow local storage to over 200tb.  in using this solution,\\nthe department saved just over a million dollars in purchasing and\\nmaintenance costs compared to the alternative. next came requirements to improve processing of future big data formats fulfilled in a red hat linux high compute cluster i designed, purchased and\\naccredited for operation in the enterprise.  improvement on big data analytical processing reduced time from\\n30 hours to 30 minutes as well as allow for more robust data thru\\nhigher selections of sensors, frequencies and range than allowed thru\\nthe traditional process.         company name    city  ,   state    senior systems analyst   02/1999   to   02/2006        i was hired to improve corporate and\\nclient communications and processing requirements which resulted in\\nthe design, build and deployment of 3 enterprise network solutions.  one\\nsolution resulted in expanding capabilities to supporting washington\\nnavy yard, norfolk virginia and hawaii support facilities. \\n\\n\\n\\n\\n\\n\\nfulfilled\\nrequirements for detecting crucial network software/hardware\\nweaknesses and developing preventive strategies and solutions for\\navoiding interruptions and increasing system security thru\\ndocumenting system layouts, wiring diagrams and addressing schema to\\nunderstand layouts and make informed solutions to upper management.\\n\\n\\n\\n          education and training      associate of science  :  electronic engineering   1980     florence darlington technical school  ,   city  ,   state       electronic engineering.     dean's list for high gpa.      class president for second year          skills        active directory  hardware engineering  information technology  red hat enterprise linux servers  ms windows servers  ms windows desktop  network design & troubleshooting  architectural diagrams  accreditation boundarys  risk management  enterprise strategies  vendor relations   desktop publishing software: photoshop, illustrator, html  team work  collaboration\n",
      "218  information technology specialist\\tgs11             experience     07/2004   to   current     information technology specialist\\tgs11    company name   －   city  ,   state      information technology specialist; supervison; project management; circuit management; licensed electrician; alarm management; alarm technician; training; supply; quality assurance kevin l.  trostle, dsn 266-4800, comm.  865) 336-4800\\nmanage the assigned it/communications environment with privileged access at the network level for the wing, geographically separated units (gsu), and tenants.  plan, coordinate, install, and continuously analyze system design, hardware and software.  develop, recommend, and install solutions and upgrades to ensure availability, integrity, efficiency, and reliability of all components of the assigned system.  ensure all performed work is captured in the remedy ticketing system.  manage telecommunications and nipr networks for the wing, gsu's, and tenant units.  continually plan, install, and analyze new hardware, software and processes to ensure networks are reliable and efficient.  serve as a focal point for ensuring functionality and operability of the assigned it/data systems/functions, voice, and wireless systems to support mission requirements.  optimize, analyze, manage, and direct installation of any new hardware or software introduced into the environment to ensure its compatibility with existing architecture, its reliability, and functionality in relation to the organization's business requirements.  oversee and initiate corrective or preventative measures to rectify immediate problems and prevent future occurrences through the cfp.  troubleshoot and diagnose system failures to isolate source of problems.  provide customer technical assistance/support for all users.  provide management with information necessary to address difficult/complex problems.  review purchase requests, sow's ensuring documentation is sufficient to justify enhancements to keep systems current.  work with the cfp/customers to resolve integration or configuration related issues.  ensure upgrades to the base it infrastructure are identified.  assist customers in developing/submitting recommendations for equipment and funds.  assist personnel in planning/developing new or additional infrastructure/architecture capabilities.  coordinate efforts between system customers, support personnel, commercial vendors to identify/resolve system anomalies.  conduct feasibility studies to identify and analyze system failures and analyzes data to determine if trends exist which forecast the need for future replacement or modification of system hardware and software.  as budget constraints dictate, evaluates alternative means of satisfying user requirements and provides management with the most technically feasible and cost efficient approaches to meet changing needs.  keep abreast of changes in technology to assist management in preparing for future enhancements.         02/2001   to   current     cyber transport/ client systems workcenter supervisor    company name   －   city  ,   state      kevin l.  trostle, dsn 266-4800, comm.  865) 336-4800\\nmanage cyber transport/client systems work center personnel.  set and adjust work priorities, evaluate, and counsel subordinates.  document training of personnel using computer based training system (tba)\\nsustain and operate systems through effective troubleshooting, repair, pmi's, system performance testing/analysis.  systems include network infrastructure equipment, cabling, voice systems, video systems, small computers, and printers\\nmaintain close working relationship with communications focal point--production requirements/remedy tickets.         07/1996   to   07/2000     f-16 ejection system technician    company name   －   city  ,   state      ronald buckman, comm.  803) 895-1190 \\ntroubleshot, removed, tested, inspected, repaired, modified, and installed explosive and non-explosive components and assemblies on ejection systems.  performed preventative maintenance on over ninety different electronically fired explosive devices ensuring proper wiring and termination.  foreign object damage monitor, briefed wing commander monthly on findings.  ran entire supply system ensuring all parts and supplies were readily available.  hazardous materials monitor.  explosive inspector.  ensured proper grounding points were present in shop to prevent electrostatic discharge to explosive components.  section workgroup manager in charge of maintaining computers and ensured needed software was installed.  shop computer security monitor.  trained and supervised personnel.  quality assurance assessor.          education and training     jun 1996     hs diploma  :   general studies    brockport high school   －   city  ,   state      general studies       may 2003     bs degree  :   electrical engineering    university of tn   －   city  ,   state      electrical engineering       november 1996     usaf, electronic principles, june 2002 to august 2002; usaf, telephone systems apprentice course, september 2002 to december 2002; usaf, aircrew egress systems apprentice course      numerous certificates for web-based training on lan fundamentals, routers, topologies, cisco networking, etc.        interests    while stationed in south carolina performed three years of volunteer electrical work for habitat for humanity.  while doing this work i learned the fundamentals of wiring a house for electric, cable, and telephone.      skills    budget, cabling, cisco, hardware, client, documentation, electrician, feasibility studies, funds, information technology, inspector, lan, materials, access, network, networking, networks, personnel, telephone systems, printers, processes, project management, quality assurance, routers, system design, technical assistance, technician, telecommunications, troubleshoot, troubleshooting, upgrades, video, wiring      additional information      awards:\\nsuperior performer, 2nd quarter 2003;  usaf achievement medal, june 2000; humanitarian service medal, january 1998; 20 crs maintenance professional of the year, 1998; airman of the quarter, may 1997; airman of the month, march 1997; airman of the month, february 1997\\nother information:\\nwhile stationed in south carolina performed three years of volunteer electrical work for habitat for humanity.  while doing this work i learned the fundamentals of wiring a house for electric, cable, and telephone.\n",
      "219                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      information technology supervisor       summary    seeking a position as an information technology specialist. over 5 years of information technology experience in the u.s. army, including over 1 year of supervisory experience. trained personnel in the set-up of it equipment, ensuring all equipment is properly connected and functioning. regularly troubleshoot and install various it equipment and systems. accountable for the maintenance and inventory of over $1 million worth of it and other communications equipment with zero losses or damages. possess a security   and microsoft certification and a secret security clearance.      highlights          excellent communication techniques  manufacturing systems integration  multidisciplinary exposure  design instruction creation  project management      complex problem solver  advanced critical thinking  sharepoint  microsoft excel, project and visio            accomplishments    army achievement medal for impacting the communications network and overall success of key resolve 13 in yong san, korea. air force achievement medal for supporting operation iraqi freedom and performing as an outstanding senior controller. certificate of achievement for outstanding support as a member of the tiger team during the windows 7 migration. good conduct medal for exemplary behavior, efficiency and fidelity in active federal military service.      experience      information technology supervisor   01/2011   to   05/2014     company name   city  ,   state       supervise up to 10 personnel at one time, delegating tasks, conducting performance evaluations and providing corrective counseling as necessary.  train personnel in the set-up and proper use of it related equipment while adhering to all policies and procedures.  responsible for the inventory of over $1 million worth of network communications equipment.  tasked by president of the united states to act as supervisor and maintain signal communications for fort bragg army base.          information technology technician   01/2009   to   01/2011     company name   city  ,   state       maintained communications equipment in order to effectively relay confidential and secret information.  utilized electronic test equipment to troubleshoot malfunctioning communications equipment and complete repairs as necessary.  regularly set up and added computer systems to a communication network, installing operation systems, accessing stored programs and utilizing ip addresses.  received training in lan/wan protocols.          radiology technologist   05/2008   to   09/2008     company name   city  ,   state       routinely performed radiological examinations in a medical clinic.  competent and experienced in the set-up and adjustment of medical devices or equipment.  regularly provided customer assistance, ensuring all patients received timely and accurate care.  accountable for the accurate documentation via electronic database and file system ensuring all confidentiality was maintained.          command post controller   10/2001   to   10/2005     company name   city  ,   state       provided command, control, communications, and information support throughout operations during peacetime, emergency, and disaster situations.  received and relayed instructions and records, submitting manual and automated data products.  disseminated time-sensitive critical information to senior leaders and support agencies.          education      certification, windows 7, microsoft, fort bragg, nc,     2012                   *certification, security  , comptia, yong san, korea,     2012                   *distinguished graduate certificate, information technology (network communications) course     2009       u.s. army   city  ,   state               certificate, it network and cisco routing, it field services branch     2009          city  ,   state               associate of science  :   radiography   2008       northwest florida state college   city  ,   state       radiography        certificate     2001       it tech prep, trumbull career and technical center     state               diploma     2001       warren g. harding   city  ,   state               skills    army, cisco, counseling, customer assistance, database, documentation, information technology, inventory, ip, lan, windows 7, network, personnel, policies, protocols, repairs, routing, san, supervisor, test equipment, troubleshoot, wan\n",
      "220                                                          information technology instructor       summary    seventeen years experience in the information technology field. seven years experience in curriculum design and computer based training development. group and project management experience for over twelve years. advanced problem solving skills and expertise. advanced customer service training and experience curriculum          data analysis          other · curriculum design          · advanced data analysis          · student counseling · learning analysis          · market analysis          · customer service training · advanced planning          · training success evaluation         · team building · articulation and development          · quantitative project analysis       · project management · implementation          · qualitative project analysis        · advanced conflict resolution · evaluation          · advanced user experience          · market driven planning expertise · computer based training design          data analysis      highlights        media design          productivity          other · photoshop          · microsoft          · network management · premier          · word          · novell console 1 · illustrator          · excel          · microsoft networking · indesign          · powerpoint          · cable wiring standards · flash          · project          · machine hardware · dreamweaver          · outlook          · windows os installation & · fireworks          · ilife          repair · soundbooth          · pages          · mac os installation & repair · quarkxpress          · numbers          · virtualization · camtasia          · keynote          · parallells · html coding          · imovie          · vmware, desktop & fusion · php / database connection          · iphoto          · course management software            experience      information technology instructor ...................................................................................................................     jan 2012   to   current      company name   －   city  ,   state     manage student learning needs.  create curriculum for it program.  manage two part time instructors.  teach three classes of twenty-two students each class per day.  manage open entry/open exit curriculum for all training in the program.  verify training outcome reports to maintain coe standards.  data metric analysis of student progress throughout the course.  answer questions of potential students and parents.  review and update training standards as needed.  new curriculum development according to market requirements customer service training tailored towards it students partner with fellow instructors to provide cross training and student interaction work with student services to assure student success counsel students on learning methods and methods for improvement.         help desk manager ­ campus d .....................................................................................................................     jan 2010   to   jan 2012      company name   －   city  ,   state     manage incoming troubleshooting calls from four state agencies.  assisted help desk staff members in resolving customer requests with first call resolution.  create and specify computer standards for the utah dept.  of health.  trained fourteen help desk staff members on help desk phone client installation and usage.  software management for dept.  of health.  manage new user creation procedure for state departments of health & natural resources.  created new user training documentation for thirty help desk staff members in the state of utah.  provide remote control support for customers throughout the state.  customer friendliness reported on several occasions to management staff, commended for ability to teach customer how to utilize their technology more effectively.         media designer ..................................................................................................................................................     jan 2009   to   jan 2010      company name   －   city  ,   state     prepare training curriculum for preparedness trainings.  designed eighteen computer based training courses for the department of health's management staff training over one hundred managers providing significant cost savings.  coordinated information technology needs for fifty preparedness staff members.  designed cover art and the multimedia presentations to give trainees after sessions, prepared over one thousand take home packets for various trainings.  served as technical lead staff member for the utah department of health's training and education center.         technical support specialist ............................................................................................................................     jan 2002   to   jan 2009      company name   －   city  ,   state     provided advanced level technical support for department staff in computer repair and service.  inventory control for department of health hardware.  created technology standards for division of health systems improvement.  served on advisory committee for mobile device policy creation.  updated department travel system from paper to online.         education      masters of education  ,   learning & technology   2012     doctorate of education; higher education, ed.d ...........................concordia university m.ed. ............................. western governor's university         learning & technology       bachelor of science  ,   information technology management   information technology management       b.s. .........     2010     western governor's university                associate of applied science  ,   multimedia technologies   multimedia technologies       a.a.s .........................     2003     utah valley university                skills    photoshop, premier, art, cable, hardware, computer repair, curriculum development, client, customer service training, database, department of health, documentation, dreamweaver, fireworks, flash, help desk, html coding, illustrator, indesign, information technology, inventory control, mac os, market, excel, microsoft networking, outlook, powerpoint, windows os, word, multimedia presentations, natural, network management, novell, php, progress, quarkxpress, staff training, technical support, user training, phone, troubleshooting, wiring\n",
      "221                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              information technology manager/analyst         professional summary    innovative and solution focused web development manager/analyst with extensive experience in program and project management. detail-oriented and skilled in identifying technology needs, creating a plan for solving them, and leading multiple teams to implement the solutions. self motivated, strong leader, and team player that works hard developing staff.  experienced in working in industry and academia.      skills        project management program management process improvement requirements gathering team leader strategic planning  results-oriented effective multi-tasker data analysis team player team building extensive technology experience          work history      information technology manager/analyst  ,     07/2006   to   current     company name   –   city  ,   state    \\n\\n\\n\\n\\n\\n\\nanalyze the technology needs of the graduate college, to develop short term and long term goals and to meet and implement the solutions to those needs by working with internal, external or mixed teams tech or non-tech teams. oversee the management of multiple websites running various software.  supervise and manage the composition of the graduate college information technology team focusing on balancing technology skills based on short and long term goals. \\ndevelop staff skills through training as needed. collect and report data to various groups across campus as well as to national agencies such as national science foundation, national institutes of health, and council of graduate schools. \\n\\n\\n   led the graduate college it team for over eight years   implemented software development lifecycle methodology    appointed to iowa state university's paperless task force to represent the graduate college   elected to the professional and scientific council to represent p&s employees  led strategic initiates for the graduate college for past three years  communication leader between faculty, staff, and central it  proficient in the use and implementation of industry it standards  regularly translate detailed program requirements into technical specifications.         manager  ,     06/2003   to   06/2006     company name   –   city  ,   state      assisted with the running of the des moines store (largest in district).  managed 25 employees.  trained employees to complete their position duties.  handled cash daily and reconciled accounts.         web communications manager  ,     01/1999   to   01/2003     company name   –   city  ,   state      developed and managed websites and web software related projects while staying within the $2 million budget of the web communications department.  directed various development teams of project managers and programmers focusing on internal and external users.  created project plans and worked with marketing and executive leadership to gain approval for projects.  regularly worked by phone or email to complete projects.      led project teams to roll out first company wide intranet, while delivering 1 month faster than original timeline.  developed new corporate website from scratch, and then led teams to roll out new website.  developed, trained, and implemented corporate web design standards across the company.         education      family financial planning (graduate certificate)  :         iowa state university   -   city  ,   state           will be a certified financial planner after completion.  :     1 1998     gpa:   gpa: 4 . 0   gpa: 4 . 0       b.s  :   marketing  ,       iowa state university   -   city  ,   state    marketing        microsoft front page certified new horizons - des moines, ia\\na ccomplishments  :     1 1999    l rolled out the first company wide intranet for a fortune 500 company. l learned two computer languages on my own to better understand the limits of what developers can do. l in 2010, elected professional and scientific representative. l implemented entire electronic thesis/dissertation solution at iowa state university. l published paper at international academy of technology education, and development (iated) conference: empowering departments across the university by using web technologies ­ 2\n",
      "                   Category\n",
      "217  INFORMATION-TECHNOLOGY\n",
      "218  INFORMATION-TECHNOLOGY\n",
      "219  INFORMATION-TECHNOLOGY\n",
      "220  INFORMATION-TECHNOLOGY\n",
      "221  INFORMATION-TECHNOLOGY\n",
      "\n",
      "Docs:\n",
      "              Job Title  \\\n",
      "0     Flutter Developer   \n",
      "1      Django Developer   \n",
      "2      Machine Learning   \n",
      "3         iOS Developer   \n",
      "4  Full Stack Developer   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             cleaned_description  \n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                we are looking for hire experts flutter developer. so you are eligible this post then apply your resume.\\njob types: full-time, part-time\\nsalary: ₹20,000.00 - ₹40,000.00 per month\\nbenefits:\\nflexible schedule\\nfood allowance\\nschedule:\\nday shift\\nsupplemental pay:\\njoining bonus\\novertime pay\\nexperience:\\ntotal work: 1 year (preferred)\\nhousing rent subsidy:\\nyes\\nindustry:\\nsoftware development\\nwork remotely:\\ntemporarily due to covid-19  \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                python/django (developer/lead) - job code(pdj - 04)\\nstrong python experience in api development (rest/rpc).\\nexperience working with api frameworks (django/flask).\\nexperience evaluating and improving the efficiency of programs in a linux environment.\\nability to effectively handle multiple tasks with a high level of accuracy and attention to detail.\\ngood verbal and written communication skills.\\nworking knowledge of sql.\\njson experience preferred.\\ngood knowledge in automated unit testing using pyunit.  \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         data scientist (contractor)\\n\\nbangalore, in\\n\\nresponsibilities\\n\\nwe are looking for a capable data scientist to join the analytics team, reporting locally in india bangalore. this person’s responsibilities include research, design and development of machine learning and deep learning algorithms to tackle a variety of fraud oriented challenges. the data scientist will work closely with software engineers and program managers to deliver end-to-end products, including: data collection in big scale and analysis, exploring different algorithmic approaches, model development, assessment and validation – all the way through production.\\n\\nqualifications\\n\\nat least 3 years of hands-on development of complex machine learning models using modern frameworks and tools, ideally python based.\\nsolid understanding of statistics and applied mathematics\\ncreative thinker with a proven ability to tackle open problems and apply non-trivial solutions.\\nexperience in software development using python, java or a similar language.\\nany graduate or m.sc. in computer science, mathematics or equivalent, preferably in machine learning\\nability to write clean and concise code\\nquick learner, independent, methodical, and detail oriented.\\nteam player, positive attitude, collaborative, good communication skills.\\ndedicated, makes things happen.\\nflexible, capable of making decisions in an ambiguous and changing environment.\\n\\nadvantages:\\n\\nprior experience as a software developer or data engineer – advantage\\nexperience with big data – advantage\\nexperience with spark – big advantage\\nexperience with deep learning frameworks (pytorch, tensorflow, keras) – advantage.\\nexperience in the telecommunication domain and/or fraud prevention - advantage  \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         job description:\\n\\nstrong framework outside of ios is always a plus\\n\\nios experience and generalist engineers with backgrounds in related technologies is a plus\\n\\na disciplined approach to development, documentation and file structure\\n\\nstrong visual design sense and excellent taste\\n\\na constant desire to improve, learn more and take things higher\\n\\nan excellent understanding of networking, mobile network issues, concurrency and threading\\n\\nexperience working with internationalized apps\\n\\nresponsibilities\\ndesign and build advanced applications for the ios platform.\\ncollaborate with cross-functional teams to define, design, and ship new features..\\nwork on bug fixing and improving application performance.\\ncontinuously discover, evaluate, and implement new technologies to maximize development efficiency.\\nhave published one or more ios apps in the app store.\\na deep familiarity with objective-c and cocoa touch.\\nexperience working with ios frameworks such as core data, core animation, core graphics and core text.\\nexperience with third-party libraries and apis.\\nworking knowledge of the general mobile landscape, architectures, trends, and emerging technologies.\\nsolid understanding of the full mobile development life cycle.\\nresponsible for working on different layers of the ios apps.\\nhelp architect and maintain our set of native mobile applications.  \n",
      "4  job responsibility full stack engineer – react role make impact petsmart transforming engineering team meet need rapidly changing retail environment role foundational helping build craft petsmart ’ prowess making react j native key framework across mobile web property working across web mobile application part building amazing mobile first customer experience impact customer store digital channel goal responsibility include act full stack developer across petsmart ’ various web mobile solution full stack engineer help build petsmart ’ competency using react j native across mobile web property partner web engineering team strategy share component across application best practice new advancement react community work product ux team review design concept offer suggestion decrease complexity maintaining spirit experience proactively make recommendation technical enhancement better performance scalability maintainability accountable delivering agile environment creates/oversees completion technical development mobile web solution work cross functional business team design develop solution based business requirement identify area improvement design implementation process tooling automated testing quality assurance mentor le experienced developer remain current latest web technology seeking integrate solution appropriate ’ bring table 5+ year hands-on experience web development 2+ year recent experience working react strong experience various j library framework redux angular vue etc expert understanding javascript html cs restful apis http networking concept full stack web development architecture expertise experience mvc object-oriented programming concept experience implementing responsive design adaptive design demonstrated strong front-end development skill especially concerning accessibility extensibility client-side computing object-oriented design pattern object-oriented cs experience sass/less/postcss framework demonstrated passion user experience design usability familiar experienced making use open source component ability address short term tactical requirement without losing site longer range strategic direction self-motivated discipline meet deadline speed accuracy professional attitude excellent written oral communication skill excellent analytical trouble-shooting skill collaborative team player ability resolve conflict constructive manner work around obstacle ensure project success b computer science equivalent team ’ growing faster pace ever investing heavily cutting-edge technology importantly _our people._ petsmart team ’ department valued business partner every area company every level associate empowered come innovative idea strategic impact business ’ take pride work “ ” behind all—for love pet click meet mike goodwin petsmart ’ cio ’ love home office offer outstanding amenity fun rewarding workplace including pet friendly environment bring pet work ! work-life balance family event movie night art event holiday festival “ top dog ” gym equipment fitness class massage therapist personal trainer “ sit & stay ” café serving fresh breakfast lunch option starbucks cart—productivity finest ! “ lil ’ paw ” learning center onsite childcare facility volunteer event petsmart charity submit resume  \n"
     ]
    }
   ],
   "source": [
    "# Preview the processed DataFrames to confirm changes\n",
    "print(\"Resumes:\")\n",
    "print(filtered_queries[['ID']].head())\n",
    "print(filtered_queries[['cleaned_text']].head())\n",
    "print(filtered_queries[['Category']].head())\n",
    "\n",
    "print(\"\\nDocs:\")\n",
    "print(documents_df[['Job Title', 'cleaned_description']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc5047-69ad-484b-b64b-12601ff164e3",
   "metadata": {},
   "source": [
    "## Building the Inverted Index\n",
    "\n",
    "1. **Load Stopwords**  \n",
    "   Load a predefined list of stopwords to exclude common, non-informative words from the index.\n",
    "\n",
    "2. **Define Tokenizer**  \n",
    "   Create a tokenizer function to split text into meaningful tokens.\n",
    "\n",
    "3. **Build Inverted Index from Filtered Resumes**  \n",
    "   Iterate through the filtered resumes and populate the inverted index, mapping each token to the list of document IDs in which it appears.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b0a02d3-f777-4c65-9c1c-bae349a6b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stopwords\n",
    "with open(\"../data/stopwords_en.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stopwords = set(word.strip().lower() for word in f if len(word.strip()) > 1)\n",
    "\n",
    "# define tokenizer\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    tokens = text.split()\n",
    "    return [t for t in tokens if len(t) > 1 and t not in stopwords and not t.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e6db9f0-4be0-418b-ba11-eb1e134614a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {}\n",
    "\n",
    "for _, row in documents_df.iterrows():\n",
    "    doc_id = row['Document ID']\n",
    "    content = row['cleaned_description']\n",
    "\n",
    "    token_counts = defaultdict(int)\n",
    "    for token in tokenize(content):\n",
    "        token_counts[token] += 1\n",
    "\n",
    "    for token, count in token_counts.items():\n",
    "        if token not in inverted_index:\n",
    "            inverted_index[token] = {\n",
    "                'total_freq': 0,\n",
    "                'doc_freq': 0,\n",
    "                'postings': []\n",
    "            }\n",
    "        inverted_index[token]['total_freq'] += count\n",
    "        inverted_index[token]['doc_freq'] += 1\n",
    "        inverted_index[token]['postings'].append((doc_id, count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ad082de-57b9-474a-87cd-a297f0064cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Inverted Index Preview (Top 15 Frequent Terms) ===\n",
      "          Index Term  Total Frequency  Document Frequency  \\\n",
      "6677      experience             9569                2115   \n",
      "19614           work             4753                1743   \n",
      "5270     development             4088                1570   \n",
      "10184      knowledge             3174                1434   \n",
      "17754           team             3030                1257   \n",
      "16670       software             2868                1164   \n",
      "5159          design             2821                1269   \n",
      "19885          years             2688                1417   \n",
      "4776            data             2638                 917   \n",
      "16528         skills             2585                1291   \n",
      "9871             job             2578                1591   \n",
      "13838      preferred             2459                 993   \n",
      "15167       required             2143                 987   \n",
      "18643  understanding             2080                 994   \n",
      "19637        working             1981                1092   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Postings (Job ID, Count)  \n",
      "6677                                                              [(0, 1), (1, 4), (2, 6), (3, 4), (4, 9), (5, 10), (6, 7), (7, 5), (8, 7), (9, 7), (10, 3), (11, 5), (12, 4), (13, 7), (14, 5), (15, 15), (16, 4), (17, 1), (18, 7), (19, 9), (20, 4), (21, 4), (22, 1), (23, 7), (24, 2), (25, 3), (26, 8), (28, 4), (29, 12), (30, 8), (31, 1), (32, 2), (33, 4), (34, 8), (35, 7), (36, 4), (37, 3), (38, 2), (39, 1), (40, 12), (41, 3), (42, 8), (43, 1), (44, 4), (45, 2), (46, 2), (47, 8), (48, 4), (50, 1), (51, 7), (52, 12), (53, 1), (54, 2), (55, 2), (56, 12), (57, 3), (58, 9), (59, 3), (60, 3), (61, 2), (62, 1), (63, 6), (64, 4), (65, 3), (66, 8), (67, 3), (68, 5), (69, 5), (70, 3), (71, 1), (72, 8), (73, 5), (74, 7), (75, 15), (76, 3), (77, 3), (78, 3), (79, 3), (80, 2), (81, 2), (82, 3), (83, 5), (84, 5), (85, 7), (86, 4), (87, 5), (88, 6), (89, 8), (90, 7), (91, 6), (92, 2), (93, 7), (95, 9), (96, 1), (97, 2), (98, 6), (99, 3), (100, 4), (101, 2), (102, 1), ...]  \n",
      "19614                                          [(0, 2), (2, 1), (3, 1), (4, 5), (5, 10), (6, 1), (9, 2), (10, 5), (11, 3), (12, 2), (13, 8), (14, 5), (15, 4), (16, 2), (18, 5), (19, 1), (20, 3), (21, 4), (22, 10), (23, 7), (24, 2), (26, 1), (28, 3), (29, 10), (30, 1), (32, 1), (33, 1), (35, 2), (36, 5), (37, 1), (38, 3), (41, 3), (42, 2), (43, 1), (44, 1), (45, 2), (48, 3), (49, 3), (51, 3), (52, 5), (53, 3), (54, 2), (55, 1), (56, 3), (58, 1), (59, 3), (60, 6), (62, 2), (63, 2), (64, 4), (65, 1), (66, 3), (67, 5), (69, 6), (70, 1), (71, 2), (72, 2), (73, 3), (75, 2), (78, 3), (79, 2), (80, 1), (81, 2), (83, 3), (84, 1), (85, 4), (86, 5), (87, 1), (88, 1), (90, 12), (91, 4), (92, 1), (93, 2), (94, 2), (95, 4), (96, 3), (98, 1), (99, 2), (100, 1), (101, 1), (102, 1), (103, 3), (104, 3), (105, 3), (106, 2), (107, 1), (108, 2), (110, 5), (111, 4), (112, 1), (114, 2), (115, 1), (116, 1), (118, 2), (119, 1), (120, 3), (121, 1), (122, 3), (125, 1), (127, 2), ...]  \n",
      "5270                                            [(0, 1), (1, 1), (2, 4), (3, 3), (4, 4), (5, 2), (6, 2), (9, 3), (10, 2), (11, 1), (12, 2), (13, 11), (14, 5), (15, 2), (16, 3), (17, 3), (18, 3), (19, 1), (22, 2), (23, 3), (24, 2), (26, 3), (27, 1), (28, 3), (29, 3), (30, 2), (32, 1), (33, 1), (34, 4), (35, 1), (37, 1), (39, 3), (41, 3), (42, 2), (44, 3), (45, 1), (48, 4), (49, 4), (52, 6), (53, 1), (54, 3), (56, 2), (57, 4), (58, 2), (59, 1), (60, 1), (61, 1), (63, 2), (64, 6), (65, 2), (66, 4), (67, 2), (68, 2), (69, 1), (70, 2), (72, 7), (73, 3), (75, 1), (77, 1), (78, 5), (79, 1), (81, 3), (82, 2), (83, 5), (84, 4), (85, 1), (86, 1), (88, 1), (91, 1), (93, 4), (95, 8), (96, 1), (97, 1), (98, 5), (99, 5), (101, 1), (102, 2), (104, 5), (105, 5), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 3), (114, 2), (115, 3), (118, 2), (119, 3), (120, 5), (121, 3), (122, 1), (124, 3), (125, 1), (127, 2), (128, 3), (129, 3), (132, 1), (133, 1), (135, 1), ...]  \n",
      "10184                                  [(1, 2), (3, 1), (5, 1), (6, 1), (7, 1), (9, 5), (10, 2), (11, 1), (12, 1), (13, 2), (14, 1), (16, 1), (17, 1), (20, 1), (21, 2), (22, 1), (23, 5), (24, 2), (25, 2), (26, 7), (30, 1), (32, 1), (33, 1), (34, 1), (35, 3), (36, 3), (37, 2), (38, 1), (39, 3), (40, 2), (41, 1), (42, 3), (43, 1), (44, 1), (45, 3), (46, 1), (47, 1), (48, 1), (49, 1), (51, 1), (52, 1), (53, 1), (54, 1), (56, 1), (57, 1), (59, 3), (64, 1), (65, 1), (66, 1), (67, 2), (69, 2), (70, 5), (71, 1), (72, 1), (73, 4), (75, 4), (77, 1), (80, 1), (84, 2), (85, 2), (86, 3), (87, 1), (88, 2), (90, 1), (93, 3), (96, 1), (97, 3), (100, 2), (101, 2), (102, 1), (103, 1), (106, 3), (108, 5), (109, 4), (110, 1), (112, 2), (115, 1), (116, 4), (117, 6), (118, 1), (119, 2), (120, 2), (121, 1), (123, 2), (124, 4), (125, 1), (127, 1), (128, 1), (130, 4), (132, 1), (133, 4), (134, 1), (138, 2), (139, 2), (140, 2), (141, 1), (142, 1), (147, 1), (148, 1), (149, 4), ...]  \n",
      "17754                   [(2, 2), (4, 7), (6, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 7), (14, 2), (15, 4), (16, 1), (18, 7), (19, 3), (20, 2), (22, 14), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 7), (30, 3), (33, 4), (34, 1), (36, 1), (42, 3), (47, 2), (48, 1), (49, 2), (51, 1), (54, 1), (56, 2), (58, 1), (61, 1), (63, 4), (67, 4), (69, 6), (72, 2), (74, 1), (75, 4), (78, 5), (79, 2), (81, 3), (83, 2), (85, 4), (86, 3), (88, 1), (90, 3), (91, 3), (92, 2), (93, 1), (94, 1), (95, 4), (98, 1), (99, 1), (102, 1), (103, 1), (105, 3), (106, 1), (108, 1), (110, 1), (111, 5), (112, 3), (115, 1), (118, 1), (119, 1), (120, 1), (124, 2), (125, 1), (127, 3), (128, 4), (129, 4), (130, 3), (131, 1), (132, 1), (133, 2), (136, 2), (137, 7), (138, 2), (139, 2), (140, 2), (141, 3), (143, 2), (145, 1), (146, 6), (148, 3), (149, 2), (150, 1), (151, 2), (152, 1), (153, 1), (154, 5), (157, 2), (163, 3), (165, 2), (167, 2), (169, 2), (171, 2), (173, 2), (174, 1), ...]  \n",
      "16670                         [(0, 1), (2, 3), (5, 5), (6, 3), (8, 1), (9, 5), (10, 4), (12, 3), (13, 6), (14, 9), (15, 4), (16, 2), (18, 1), (19, 1), (20, 1), (23, 9), (24, 2), (26, 2), (28, 3), (29, 3), (30, 3), (31, 1), (32, 1), (34, 4), (37, 1), (38, 2), (39, 4), (40, 1), (41, 3), (42, 3), (44, 1), (46, 1), (48, 1), (49, 8), (52, 5), (53, 2), (54, 1), (58, 1), (63, 2), (64, 1), (65, 1), (67, 6), (68, 1), (72, 1), (73, 2), (74, 2), (75, 1), (77, 1), (78, 1), (79, 4), (82, 2), (84, 1), (85, 1), (87, 6), (93, 3), (94, 2), (95, 4), (98, 7), (99, 4), (100, 1), (102, 2), (104, 1), (105, 3), (111, 3), (112, 3), (115, 2), (120, 2), (124, 1), (125, 1), (126, 2), (127, 2), (128, 5), (132, 1), (133, 2), (134, 1), (136, 1), (137, 5), (138, 10), (139, 1), (140, 2), (141, 5), (145, 1), (146, 3), (148, 3), (150, 1), (152, 1), (154, 1), (157, 3), (161, 2), (163, 3), (165, 1), (166, 1), (167, 1), (169, 1), (171, 4), (173, 1), (175, 2), (176, 8), (177, 2), (181, 4), ...]  \n",
      "5159                   [(2, 1), (3, 3), (4, 7), (5, 2), (9, 1), (10, 1), (12, 1), (13, 8), (14, 4), (15, 1), (18, 4), (19, 3), (20, 1), (21, 1), (23, 5), (24, 1), (25, 3), (26, 1), (32, 1), (33, 1), (34, 1), (37, 1), (39, 2), (42, 3), (45, 2), (46, 1), (48, 3), (49, 3), (51, 1), (52, 3), (53, 2), (57, 4), (59, 3), (63, 3), (64, 3), (69, 2), (71, 1), (72, 10), (75, 1), (77, 1), (79, 1), (80, 1), (81, 1), (83, 1), (84, 3), (85, 2), (87, 2), (88, 2), (91, 1), (93, 9), (95, 1), (98, 2), (99, 1), (102, 1), (103, 2), (104, 1), (105, 7), (106, 3), (108, 1), (110, 2), (112, 3), (115, 2), (119, 1), (121, 2), (122, 1), (124, 3), (127, 1), (128, 3), (129, 3), (130, 1), (131, 1), (133, 2), (137, 1), (138, 3), (140, 1), (141, 1), (146, 3), (148, 2), (149, 2), (151, 2), (152, 1), (153, 1), (155, 1), (157, 3), (158, 1), (161, 2), (162, 1), (163, 2), (165, 4), (166, 2), (167, 1), (169, 2), (170, 1), (171, 3), (172, 3), (173, 1), (174, 1), (176, 2), (177, 2), (180, 1), ...]  \n",
      "19885                   [(2, 1), (5, 2), (7, 1), (9, 1), (11, 1), (13, 2), (14, 6), (15, 3), (16, 1), (17, 1), (19, 1), (21, 1), (22, 1), (28, 1), (29, 2), (30, 3), (31, 1), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (40, 6), (42, 1), (44, 1), (50, 1), (51, 2), (52, 5), (55, 1), (56, 1), (58, 1), (59, 3), (62, 2), (63, 3), (64, 2), (68, 2), (70, 2), (71, 1), (73, 4), (74, 3), (75, 2), (76, 1), (77, 1), (81, 1), (84, 1), (85, 3), (87, 3), (89, 3), (90, 4), (96, 2), (97, 1), (98, 1), (99, 1), (100, 1), (102, 2), (104, 2), (105, 2), (106, 1), (107, 3), (108, 2), (109, 3), (110, 3), (112, 1), (115, 1), (117, 1), (118, 4), (119, 2), (120, 4), (121, 1), (122, 2), (123, 1), (124, 1), (126, 2), (127, 1), (128, 2), (130, 1), (131, 2), (132, 3), (133, 1), (134, 1), (137, 1), (139, 3), (141, 4), (143, 3), (144, 1), (145, 5), (147, 1), (149, 1), (150, 1), (151, 1), (152, 3), (155, 1), (157, 2), (158, 4), (159, 2), (161, 1), (163, 1), (168, 4), (169, 1), ...]  \n",
      "4776         [(2, 6), (3, 1), (5, 1), (9, 2), (10, 1), (11, 1), (12, 9), (13, 5), (15, 1), (16, 1), (18, 4), (19, 1), (20, 1), (23, 2), (25, 1), (27, 1), (29, 1), (30, 10), (33, 3), (37, 1), (39, 3), (46, 7), (48, 1), (49, 1), (51, 6), (52, 2), (53, 1), (58, 3), (60, 10), (63, 5), (64, 1), (69, 4), (74, 1), (75, 3), (78, 1), (79, 1), (80, 1), (83, 6), (85, 5), (88, 3), (90, 6), (91, 2), (92, 1), (93, 1), (96, 7), (98, 2), (100, 5), (102, 1), (103, 1), (104, 2), (106, 1), (108, 8), (111, 1), (115, 1), (116, 1), (119, 1), (124, 2), (127, 1), (129, 1), (136, 2), (138, 2), (139, 1), (140, 1), (143, 15), (148, 1), (149, 1), (154, 1), (155, 1), (157, 3), (158, 1), (163, 4), (168, 6), (170, 4), (173, 1), (181, 3), (184, 1), (189, 1), (192, 1), (195, 1), (196, 1), (198, 2), (203, 1), (206, 3), (210, 1), (212, 1), (213, 4), (214, 1), (220, 2), (222, 1), (224, 1), (226, 1), (234, 4), (235, 2), (236, 1), (239, 4), (241, 2), (243, 1), (244, 2), (246, 1), (250, 1), ...]  \n",
      "16528                           [(1, 1), (2, 1), (7, 1), (8, 2), (9, 5), (11, 1), (12, 2), (13, 4), (14, 1), (15, 3), (16, 2), (17, 1), (21, 1), (22, 4), (24, 3), (26, 4), (28, 3), (29, 1), (30, 1), (31, 1), (32, 1), (33, 2), (34, 2), (35, 3), (36, 1), (37, 1), (39, 1), (40, 5), (42, 2), (46, 1), (47, 2), (50, 1), (51, 1), (52, 1), (53, 1), (54, 3), (56, 2), (57, 3), (58, 1), (59, 2), (60, 1), (62, 1), (63, 4), (66, 1), (67, 1), (68, 1), (70, 1), (71, 1), (73, 1), (74, 3), (75, 1), (77, 2), (81, 1), (84, 2), (85, 2), (87, 2), (90, 2), (91, 3), (93, 2), (96, 1), (99, 1), (100, 3), (105, 2), (108, 2), (111, 2), (113, 1), (114, 1), (116, 1), (118, 2), (119, 2), (121, 1), (122, 5), (123, 2), (124, 1), (127, 2), (128, 1), (133, 3), (135, 1), (137, 4), (141, 2), (143, 5), (149, 2), (150, 2), (151, 2), (155, 2), (157, 3), (158, 2), (160, 1), (161, 1), (162, 1), (163, 4), (164, 1), (165, 2), (166, 1), (167, 3), (168, 1), (169, 1), (170, 2), (171, 1), (172, 2), ...]  \n",
      "9871                               [(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 3), (7, 3), (9, 3), (11, 1), (14, 6), (16, 2), (17, 2), (18, 3), (19, 1), (21, 1), (23, 3), (24, 2), (25, 2), (27, 1), (29, 1), (31, 1), (32, 1), (34, 1), (35, 1), (36, 1), (38, 2), (39, 1), (41, 1), (43, 1), (44, 1), (45, 2), (46, 1), (48, 1), (51, 1), (52, 2), (53, 1), (54, 1), (55, 1), (56, 2), (57, 1), (58, 4), (59, 1), (65, 1), (66, 2), (70, 1), (71, 1), (73, 1), (75, 1), (77, 2), (80, 1), (81, 2), (85, 1), (86, 6), (87, 2), (90, 1), (91, 1), (92, 3), (93, 1), (95, 1), (96, 3), (99, 1), (103, 2), (106, 1), (107, 1), (108, 1), (109, 3), (110, 1), (111, 1), (113, 3), (114, 2), (115, 1), (116, 1), (117, 1), (118, 1), (119, 2), (120, 1), (121, 1), (122, 1), (123, 1), (125, 2), (128, 3), (131, 2), (132, 1), (134, 2), (135, 1), (137, 3), (138, 1), (139, 4), (141, 3), (142, 3), (144, 1), (145, 1), (147, 1), (148, 1), (149, 1), (152, 1), (153, 6), (155, 1), (156, 1), (158, 2), ...]  \n",
      "13838       [(0, 1), (1, 1), (11, 2), (12, 2), (14, 2), (15, 1), (20, 1), (21, 4), (23, 1), (24, 5), (26, 2), (29, 1), (30, 1), (32, 5), (33, 2), (35, 1), (38, 4), (43, 1), (45, 1), (50, 1), (52, 3), (54, 5), (57, 2), (58, 1), (59, 1), (60, 4), (63, 1), (65, 2), (66, 3), (67, 1), (70, 2), (73, 5), (74, 1), (78, 1), (79, 2), (80, 2), (83, 3), (85, 3), (86, 1), (87, 2), (90, 2), (91, 3), (92, 1), (99, 1), (104, 2), (106, 6), (107, 2), (110, 4), (111, 1), (114, 5), (117, 3), (118, 3), (119, 1), (120, 5), (126, 1), (128, 1), (132, 1), (134, 3), (135, 4), (137, 1), (138, 1), (139, 3), (140, 1), (141, 6), (142, 4), (145, 1), (148, 1), (151, 1), (155, 2), (156, 2), (158, 3), (163, 3), (164, 1), (165, 1), (166, 2), (168, 4), (169, 3), (172, 2), (174, 4), (176, 2), (178, 2), (179, 1), (180, 1), (181, 4), (182, 3), (183, 4), (186, 2), (188, 4), (190, 1), (191, 2), (194, 5), (196, 5), (197, 2), (200, 5), (202, 2), (203, 1), (204, 2), (206, 5), (207, 1), (208, 1), ...]  \n",
      "15167  [(5, 2), (7, 1), (10, 2), (11, 1), (14, 4), (16, 2), (20, 2), (23, 1), (24, 1), (26, 1), (29, 3), (35, 1), (36, 4), (39, 1), (40, 1), (42, 1), (45, 9), (49, 1), (51, 1), (52, 1), (53, 2), (54, 1), (56, 1), (58, 1), (59, 3), (60, 3), (62, 2), (67, 2), (68, 1), (71, 1), (72, 1), (75, 1), (83, 1), (85, 4), (86, 7), (88, 4), (90, 2), (91, 2), (99, 1), (104, 2), (105, 1), (107, 4), (108, 1), (111, 2), (114, 1), (116, 2), (117, 3), (118, 1), (119, 3), (121, 1), (127, 1), (128, 1), (131, 2), (132, 2), (133, 4), (135, 2), (139, 5), (144, 2), (145, 1), (146, 1), (149, 1), (150, 1), (152, 4), (153, 4), (155, 2), (157, 1), (158, 4), (164, 2), (167, 2), (168, 1), (169, 1), (172, 1), (176, 4), (179, 4), (180, 5), (182, 1), (186, 1), (187, 1), (188, 4), (191, 1), (197, 2), (199, 1), (204, 2), (206, 3), (207, 1), (208, 3), (210, 1), (211, 1), (214, 1), (216, 1), (224, 1), (225, 2), (227, 2), (229, 1), (234, 4), (237, 4), (239, 1), (240, 1), (241, 4), (244, 3), ...]  \n",
      "18643           [(2, 1), (3, 2), (4, 1), (13, 4), (17, 1), (19, 1), (20, 2), (21, 1), (25, 2), (29, 5), (31, 2), (32, 1), (37, 1), (39, 7), (40, 1), (41, 1), (42, 1), (44, 1), (45, 2), (46, 1), (48, 1), (49, 1), (52, 3), (53, 2), (54, 1), (56, 1), (57, 6), (59, 1), (60, 5), (63, 5), (64, 1), (65, 1), (67, 2), (72, 1), (75, 3), (76, 2), (79, 2), (80, 4), (82, 1), (85, 1), (89, 1), (90, 2), (91, 3), (93, 5), (96, 1), (98, 3), (99, 2), (100, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 2), (108, 3), (110, 1), (112, 3), (115, 1), (116, 1), (118, 1), (121, 1), (123, 4), (124, 1), (126, 2), (128, 1), (137, 1), (138, 6), (149, 1), (150, 2), (153, 1), (158, 2), (163, 2), (165, 1), (166, 3), (169, 5), (170, 5), (172, 1), (184, 1), (186, 1), (189, 1), (191, 5), (194, 1), (195, 1), (198, 1), (200, 1), (204, 3), (206, 1), (207, 2), (208, 1), (209, 2), (210, 1), (211, 1), (214, 1), (215, 6), (216, 2), (218, 1), (220, 6), (224, 3), (225, 9), (228, 2), (230, 1), ...]  \n",
      "19637                     [(1, 2), (3, 4), (4, 2), (5, 2), (8, 1), (11, 1), (12, 1), (13, 3), (14, 1), (16, 2), (19, 1), (21, 3), (22, 1), (26, 4), (28, 1), (29, 3), (30, 1), (33, 2), (34, 2), (37, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 4), (48, 4), (52, 2), (53, 1), (54, 1), (56, 3), (57, 3), (58, 3), (59, 1), (61, 1), (63, 2), (64, 2), (67, 2), (68, 1), (69, 1), (74, 2), (75, 1), (77, 1), (78, 3), (81, 1), (83, 3), (84, 1), (85, 2), (86, 1), (90, 2), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (103, 1), (104, 1), (108, 1), (115, 1), (116, 4), (121, 2), (123, 1), (127, 1), (130, 1), (136, 3), (138, 1), (140, 1), (141, 4), (143, 6), (145, 1), (148, 2), (149, 2), (153, 1), (154, 1), (155, 2), (160, 1), (161, 1), (163, 2), (165, 3), (166, 2), (168, 2), (169, 4), (170, 1), (172, 1), (173, 1), (174, 3), (176, 1), (177, 1), (178, 1), (180, 1), (185, 1), (186, 1), (187, 1), (191, 1), (198, 1), (201, 2), (203, 3), (204, 2), (205, 2), (206, 1), ...]  \n"
     ]
    }
   ],
   "source": [
    "# Display a preview of the inverted index (first 15 terms by alphabetical order)\n",
    "index_table = []\n",
    "for token in sorted(inverted_index):\n",
    "    entry = inverted_index[token]\n",
    "    index_table.append({\n",
    "        'Index Term': token,\n",
    "        'Total Frequency': entry['total_freq'],\n",
    "        'Document Frequency': entry['doc_freq'],\n",
    "        'Postings (Job ID, Count)': entry['postings']\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(index_table)\n",
    "\n",
    "df = df.sort_values(by='Total Frequency', ascending=False)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(\"=== Inverted Index Preview (Top 15 Frequent Terms) ===\")\n",
    "print(df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "594befd5-3b8c-4cbc-9473-69f088de2711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 20 Most Frequent Tokens in Job Descriptions (Excluding Stopwords) ===\n",
      "[('experience', 9569), ('work', 4753), ('development', 4088), ('knowledge', 3174), ('team', 3030), ('software', 2868), ('design', 2821), ('years', 2688), ('data', 2638), ('skills', 2585), ('job', 2578), ('preferred', 2459), ('required', 2143), ('understanding', 2080), ('working', 1981), ('application', 1911), ('year', 1895), ('strong', 1849), ('web', 1810), ('code', 1725)]\n"
     ]
    }
   ],
   "source": [
    "all_tokens = []\n",
    "for text in documents_df['cleaned_description']:\n",
    "    all_tokens.extend(tokenize(text))\n",
    "\n",
    "print(\"\\n=== Top 20 Most Frequent Tokens in Job Descriptions (Excluding Stopwords) ===\")\n",
    "print(Counter(all_tokens).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd29e89e-1ad7-442c-8743-1fb635c541d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_tfidf_scores(query, inverted_index, total_docs, top_k=10):\n",
    "    query_tokens = tokenize(query)\n",
    "    \n",
    "    query_tf = defaultdict(int) # count query token frequencies\n",
    "    for token in query_tokens:\n",
    "        query_tf[token] += 1\n",
    "\n",
    "    idf = {}\n",
    "    for token in query_tf:\n",
    "        if token in inverted_index:\n",
    "            df = inverted_index[token]['doc_freq']\n",
    "            idf[token] = math.log(total_docs / df)  # compute IDF for each token in query\n",
    "        else:\n",
    "            idf[token] = 0  # if unseen token then ignore it\n",
    "\n",
    "\n",
    "    # ompute TF-IDF for the query and its norm\n",
    "    query_tfidf = {}\n",
    "    for token in query_tf:\n",
    "        query_tfidf[token] = query_tf[token] * idf[token]\n",
    "\n",
    "    query_norm = math.sqrt(sum(val**2 for val in query_tfidf.values()))  # ||Q||\n",
    "\n",
    "    scores = defaultdict(float)    # dot product numerator\n",
    "    doc_norms = defaultdict(float) # track ||D|| per doc\n",
    "\n",
    "    for token, q_tfidf in query_tfidf.items():\n",
    "        if token not in inverted_index:\n",
    "            continue\n",
    "        postings = inverted_index[token]['postings']\n",
    "        idf_val = idf[token]\n",
    "\n",
    "        for doc_id, tf in postings:\n",
    "            d_tfidf = tf * idf_val\n",
    "            scores[doc_id] += q_tfidf * d_tfidf    # dot product Q·D\n",
    "            doc_norms[doc_id] += d_tfidf ** 2      # sum squares for ||D||\n",
    "\n",
    "    # finalize cosine similarity\n",
    "    cosine_scores = {}\n",
    "    for doc_id in scores:\n",
    "        doc_norm = math.sqrt(doc_norms[doc_id])\n",
    "        if doc_norm == 0 or query_norm == 0:\n",
    "            cosine_scores[doc_id] = 0\n",
    "        else:\n",
    "            cosine_scores[doc_id] = scores[doc_id] / (query_norm * doc_norm)\n",
    "\n",
    "    ranked = sorted(cosine_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return ranked[:top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5760c7-81b8-4bbf-8583-886e83f1b3c5",
   "metadata": {},
   "source": [
    "## TF-IDF: Match Jobs to Uploaded PDF Resume\n",
    "\n",
    "This function uses the existing TF-IDF scoring system to retrieve the top-k job matches for a user-uploaded PDF resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d973dab4-7d2e-4193-91a6-bd0410a20862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_pdf_resume_tfidf(pdf_path, inverted_index, job_df, total_docs, top_k=10):\n",
    "    cleaned_resume = extract_and_clean_pdf_resume(pdf_path)\n",
    "    \n",
    "    results = compute_tfidf_scores(\n",
    "        query=cleaned_resume,\n",
    "        inverted_index=inverted_index,\n",
    "        total_docs=total_docs,\n",
    "        top_k=top_k\n",
    "    )\n",
    "    \n",
    "    print(\"=== TF-IDF Top Job Matches ===\")\n",
    "    for rank, (doc_id, score) in enumerate(results, 1):\n",
    "        title = job_df.loc[doc_id, 'Job Title']\n",
    "        print(f\"{rank}. {title} (Score: {score:.4f})\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2aeff75-3cac-4d87-a70d-f230acb8e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_job_to_resumes_tfidf(job_index, job_text, job_title, resumes_df, top_k=10):\n",
    "    \"\"\"\n",
    "    Match a job description to top resumes using TF-IDF.\n",
    "    \"\"\"\n",
    "    total_docs = len(resumes_df)\n",
    "    \n",
    "    # Build inverted index over resumes\n",
    "    resume_inverted_index = {}\n",
    "    for _, row in resumes_df.iterrows():\n",
    "        doc_id = row['ID']\n",
    "        content = row['cleaned_text']\n",
    "        token_counts = defaultdict(int)\n",
    "        for token in tokenize(content):\n",
    "            token_counts[token] += 1\n",
    "        for token, count in token_counts.items():\n",
    "            if token not in resume_inverted_index:\n",
    "                resume_inverted_index[token] = {\n",
    "                    'total_freq': 0,\n",
    "                    'doc_freq': 0,\n",
    "                    'postings': []\n",
    "                }\n",
    "            resume_inverted_index[token]['total_freq'] += count\n",
    "            resume_inverted_index[token]['doc_freq'] += 1\n",
    "            resume_inverted_index[token]['postings'].append((doc_id, count))\n",
    "\n",
    "    # Compute similarity\n",
    "    results = compute_tfidf_scores(job_text, resume_inverted_index, total_docs, top_k=top_k)\n",
    "\n",
    "    print(f\"\\n=== TF-IDF Top Resume Matches for Job #{job_index}: {job_title} ===\")\n",
    "    for rank, (doc_id, score) in enumerate(results, 1):\n",
    "        print(f\"{rank}. Resume ID: {doc_id} (Score: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01a42790-0118-4770-81ae-3007bba30a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TF-IDF Top Resume Matches for Job #0: Flutter Developer ===\n",
      "1. Resume ID: 27058381 (Score: 0.4165)\n",
      "2. Resume ID: 32959732 (Score: 0.3144)\n",
      "3. Resume ID: 90867631 (Score: 0.3090)\n",
      "4. Resume ID: 27372171 (Score: 0.2782)\n",
      "5. Resume ID: 64017585 (Score: 0.2771)\n",
      "6. Resume ID: 22450718 (Score: 0.2712)\n",
      "7. Resume ID: 10553553 (Score: 0.2710)\n",
      "8. Resume ID: 18159866 (Score: 0.2699)\n",
      "9. Resume ID: 51363762 (Score: 0.2637)\n",
      "10. Resume ID: 10265057 (Score: 0.2614)\n"
     ]
    }
   ],
   "source": [
    "# Example: Pick first job description to test TF-IDF-based reverse matching\n",
    "sample_job = documents_df.iloc[0]\n",
    "job_index = sample_job['Document ID']\n",
    "job_text = sample_job['cleaned_description']\n",
    "job_title = sample_job['Job Title']\n",
    "\n",
    "# Match this job to resumes\n",
    "match_job_to_resumes_tfidf(\n",
    "    job_index=job_index,\n",
    "    job_text=job_text,\n",
    "    job_title=job_title,\n",
    "    resumes_df=filtered_queries,\n",
    "    top_k=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "85deda33-4482-48da-ae18-628e7f4212a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top Job Matches for Resume ID: 36856210 ===\n",
      "1. Database Administrator (Score: 0.4437)\n",
      "2. Database Administrator (Score: 0.3455)\n",
      "3. Database Administrator (Score: 0.3129)\n",
      "4. Machine Learning (Score: 0.3092)\n",
      "5. DevOps Engineer (Score: 0.2904)\n",
      "6. Database Administrator (Score: 0.2877)\n",
      "7. Network Administrator (Score: 0.2868)\n",
      "8. Database Administrator (Score: 0.2841)\n",
      "9. Network Administrator (Score: 0.2839)\n",
      "10. DevOps Engineer (Score: 0.2809)\n"
     ]
    }
   ],
   "source": [
    "# Pick a resume to test\n",
    "resume_row = filtered_queries.iloc[0]\n",
    "resume_id = resume_row[\"ID\"]\n",
    "query = resume_row[\"cleaned_text\"]\n",
    "total_docs = len(documents_df)\n",
    "\n",
    "results = compute_tfidf_scores(query, inverted_index, total_docs, top_k=10)\n",
    "\n",
    "print(f\"=== Top Job Matches for Resume ID: {resume_id} ===\")\n",
    "for i, (doc_id, score) in enumerate(results, 1):\n",
    "    job_title = documents_df[documents_df['Document ID'] == doc_id]['Job Title'].values[0]\n",
    "    print(f\"{i}. {job_title} (Score: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223a2841-f0d7-492b-b87b-bb20a6702d15",
   "metadata": {},
   "source": [
    "## Save TF-IDF Job Matches for All Resumes\n",
    "\n",
    "This function loops through each resume in the dataset, retrieves the top matching job descriptions using TF-IDF cosine similarity, and saves the results to a CSV file.\n",
    "\n",
    "### Output Columns:\n",
    "- `Resume_ID`\n",
    "- `Rank`\n",
    "- `Matched_Job_ID`\n",
    "- `Job_Title`\n",
    "- `TFIDF_Score`\n",
    "\n",
    "### Usage Example:\n",
    "```python\n",
    "save_tfidf_results_for_all_resumes(filtered_queries, documents_df, inverted_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e8ddf3ef-62f2-4096-9b71-0fb5d3c5e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tfidf_results_for_all_resumes(filtered_queries, documents_df, inverted_index, output_path=\"tfidf_resume_to_jobs.csv\", top_k=10):\n",
    "    total_docs = len(documents_df)\n",
    "    output_rows = []\n",
    "\n",
    "    for i, row in filtered_queries.iterrows():\n",
    "        resume_id = row.get(\"ID\", i)\n",
    "        resume_text = row['cleaned_text']\n",
    "\n",
    "        results = compute_tfidf_scores(resume_text, inverted_index, total_docs, top_k=top_k)\n",
    "\n",
    "        for rank, (job_id, score) in enumerate(results, start=1):\n",
    "            job_row = documents_df[documents_df['Document ID'] == job_id]\n",
    "            job_title = job_row['Job Title'].values[0] if not job_row.empty else \"Unknown\"\n",
    "\n",
    "            output_rows.append({\n",
    "                \"Resume_ID\": resume_id,\n",
    "                \"Rank\": rank,\n",
    "                \"Matched_Job_ID\": job_id,\n",
    "                \"Job_Title\": job_title,\n",
    "                \"TFIDF_Score\": score\n",
    "            })\n",
    "\n",
    "    tfidf_output_df = pd.DataFrame(output_rows)\n",
    "    tfidf_output_df.to_csv(output_path, index=False)\n",
    "    print(f\"TF-IDF matches saved to '{output_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "751646c1-5310-4dd2-8995-824f74336ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matches saved to 'tfidf_resume_to_jobs.csv'\n"
     ]
    }
   ],
   "source": [
    "save_tfidf_results_for_all_resumes(filtered_queries, documents_df, inverted_index) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc1bab2-e19a-441c-92bc-9ea1d4a5c160",
   "metadata": {},
   "source": [
    "## Precision, Recall, and F1 Evaluation\n",
    "\n",
    "In this section, we evaluate the effectiveness of our retrieval system using standard IR metrics:\n",
    "- **Precision@k**: What proportion of the top-k results are relevant?\n",
    "- **Recall@k**: What proportion of all relevant results were returned in the top-k?\n",
    "- **F1@k**: Harmonic mean of Precision and Recall — balances both.\n",
    "\n",
    "We evaluate each resume (Sue, RDH, Shang) against a manually selected set of job descriptions that are deemed relevant. Both **TF-IDF** and **LLM**-based models are used for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "57bb4672-cbe3-4992-b518-0f3ac4ee817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall, F1 @ k\n",
    "def precision_at_k(retrieved, relevant, k):\n",
    "    retrieved_k = retrieved[:k]\n",
    "    relevant_set = set(relevant)\n",
    "    hits = sum(1 for item in retrieved_k if item in relevant_set)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(retrieved, relevant, k):\n",
    "    retrieved_k = retrieved[:k]\n",
    "    relevant_set = set(relevant)\n",
    "    hits = sum(1 for item in retrieved_k if item in relevant_set)\n",
    "    return hits / len(relevant) if relevant else 0\n",
    "\n",
    "def f1_at_k(retrieved, relevant, k):\n",
    "    p = precision_at_k(retrieved, relevant, k)\n",
    "    r = recall_at_k(retrieved, relevant, k)\n",
    "    return (2 * p * r) / (p + r) if (p + r) else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d6ecaf1a-2644-416b-99ef-12c187974d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant jobs for each resume\n",
    "sue_relevant = documents_df[documents_df['Job Title'] == 'Machine Learning']['Document ID'].values.tolist()\n",
    "RDH_relevant = documents_df[documents_df['Job Title'].isin(['DevOps Engineer','Software Engineer'])]['Document ID'].values.tolist()\n",
    "shang_relevant = documents_df[documents_df['Job Title'].isin(['DevOps Engineer','Software Engineer'])]['Document ID'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5573d4-b3e4-476b-b365-b245017b0624",
   "metadata": {},
   "source": [
    "### Evaluation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "75f43e36-85fc-49a7-90c8-c2e8850e6e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TF-IDF Top Job Matches ===\n",
      "1. Django Developer (Score: 0.3518)\n",
      "2. Machine Learning (Score: 0.3420)\n",
      "3. PHP Developer (Score: 0.3250)\n",
      "4. Java Developer (Score: 0.3189)\n",
      "5. Machine Learning (Score: 0.3049)\n",
      "6. Java Developer (Score: 0.2996)\n",
      "7. Machine Learning (Score: 0.2883)\n",
      "8. Machine Learning (Score: 0.2837)\n",
      "9. JavaScript Developer (Score: 0.2836)\n",
      "10. Machine Learning (Score: 0.2836)\n",
      "=== TF-IDF Top Job Matches ===\n",
      "1. Django Developer (Score: 0.4331)\n",
      "2. Java Developer (Score: 0.3332)\n",
      "3. Database Administrator (Score: 0.3291)\n",
      "4. Full Stack Developer (Score: 0.3058)\n",
      "5. JavaScript Developer (Score: 0.2922)\n",
      "6. Database Administrator (Score: 0.2714)\n",
      "7. DevOps Engineer (Score: 0.2492)\n",
      "8. Database Administrator (Score: 0.2382)\n",
      "9. Java Developer (Score: 0.2360)\n",
      "10. Database Administrator (Score: 0.2330)\n",
      "=== TF-IDF Top Job Matches ===\n",
      "1. Database Administrator (Score: 0.3293)\n",
      "2. DevOps Engineer (Score: 0.3187)\n",
      "3. DevOps Engineer (Score: 0.3151)\n",
      "4. DevOps Engineer (Score: 0.3137)\n",
      "5. DevOps Engineer (Score: 0.3136)\n",
      "6. DevOps Engineer (Score: 0.3077)\n",
      "7. DevOps Engineer (Score: 0.3070)\n",
      "8. DevOps Engineer (Score: 0.3058)\n",
      "9. DevOps Engineer (Score: 0.3005)\n",
      "10. DevOps Engineer (Score: 0.2996)\n",
      "\n",
      "=== TF-IDF Evaluation Metrics @10 ===\n",
      "Sue TF-IDF → P: 0.5 R: 0.03289473684210526 F1: 0.061728395061728385\n",
      "RDH TF-IDF → P: 0.0 R: 0 F1: 0\n",
      "Shang TF-IDF → P: 0.0 R: 0.0 F1: 0\n"
     ]
    }
   ],
   "source": [
    "# === Ground truth mapping ===\n",
    "sue_relevant = documents_df[documents_df['Job Title'] == 'Machine Learning']['Document ID'].values.tolist()\n",
    "rdh_relevant = documents_df[documents_df['Job Title'] == 'Cloud Engineer']['Document ID'].values.tolist()\n",
    "shang_relevant = documents_df[documents_df['Job Title'] == 'Software Engineer']['Document ID'].values.tolist()\n",
    "\n",
    "# === TF-IDF retrievals ===\n",
    "Sue_tfidf_results = match_pdf_resume_tfidf(\"../data/Sue Yang Resume.pdf\", inverted_index, documents_df, total_docs=len(documents_df))\n",
    "RDH_tfidf_results = match_pdf_resume_tfidf(\"../data/RDH Resume.pdf\", inverted_index, documents_df, total_docs=len(documents_df))\n",
    "Shang_tfidf_results = match_pdf_resume_tfidf(\"../data/Shang Andrews Resume 0.1.3.pdf\", inverted_index, documents_df, total_docs=len(documents_df))\n",
    "\n",
    "# === Extract only the retrieved doc IDs ===\n",
    "Sue_tfidf_retrieved = [item[0] for item in Sue_tfidf_results]\n",
    "RDH_tfidf_retrieved = [item[0] for item in RDH_tfidf_results]\n",
    "Shang_tfidf_retrieved = [item[0] for item in Shang_tfidf_results]\n",
    "\n",
    "# === Precision, Recall, F1 @ 10 ===\n",
    "print(\"\\n=== TF-IDF Evaluation Metrics @10 ===\")\n",
    "print(\"Sue TF-IDF →\",\n",
    "      \"P:\", precision_at_k(Sue_tfidf_retrieved, sue_relevant, 10),\n",
    "      \"R:\", recall_at_k(Sue_tfidf_retrieved, sue_relevant, 10),\n",
    "      \"F1:\", f1_at_k(Sue_tfidf_retrieved, sue_relevant, 10))\n",
    "\n",
    "print(\"RDH TF-IDF →\",\n",
    "      \"P:\", precision_at_k(RDH_tfidf_retrieved, rdh_relevant, 10),\n",
    "      \"R:\", recall_at_k(RDH_tfidf_retrieved, rdh_relevant, 10),\n",
    "      \"F1:\", f1_at_k(RDH_tfidf_retrieved, rdh_relevant, 10))\n",
    "\n",
    "print(\"Shang TF-IDF →\",\n",
    "      \"P:\", precision_at_k(Shang_tfidf_retrieved, shang_relevant, 10),\n",
    "      \"R:\", recall_at_k(Shang_tfidf_retrieved, shang_relevant, 10),\n",
    "      \"F1:\", f1_at_k(Shang_tfidf_retrieved, shang_relevant, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f55b7c3-3025-4a63-bf82-e69c9c59dd50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
